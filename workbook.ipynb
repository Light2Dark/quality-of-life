{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missing locations for APIMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "\n",
    "load_dotenv()\n",
    "weather_api_key = os.getenv(\"WEATHER_API\")\n",
    "\n",
    "# https://apims.doe.gov.my/data/public_v2/CAQM/hours24/2024/10/29/0000.json\n",
    "# https://apims.doe.gov.my/data/public_v2/MCAQM/mcaqmhours24/2024/10/29/0000.json\n",
    "# df = pd.read_json(\"aq.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_list = []\n",
    "for i in range(1, len(df)):\n",
    "    location_list.append(df.loc[i][0][1])\n",
    "\n",
    "df_locations = pd.read_csv(\"dbt/seeds/state_locations.csv\")\n",
    "db_locs = df_locations[\"Identifying_Location\"].to_list()\n",
    "\n",
    "for loc in location_list:\n",
    "    if loc not in db_locs:\n",
    "        print(loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking weather API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.wunderground.com/weather/my/bayan-lepas/IAYERI1?utm_source=HomeCard&utm_content=CurrentCondition&cm_ven=HomeCardCurrentCondition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://api.weather.com/v2/pws/history/all?stationId=IPENAN5&format=json&units=m&date=20241001&numericPrecision=decimal&apiKey={weather_api_key}\n",
    "\n",
    "20240101\n",
    "- IPENAN4\n",
    "- IPENAN5\n",
    "- IRANTA13\n",
    "- IRANTA14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    f\"https://api1.weather.com/v2/vector-api/products/614/features?x=100&y=62&lod=8&apiKey={weather_api_key}&tile-size=512&time=1730305800000-1730306700000:7&time=1730304900000-1730305800000:23&time=1730304000000-1730304900000:37&time=1730303100000-1730304000000:52&time=1730302200000-1730303100000:67&stepped=true\",\n",
    "    \n",
    "    f\"https://api.weather.com/v2/vector-api/products/5999/features?x=25&y=15&lod=6&apiKey={weather_api_key}&tile-size=512&time=1730337604000&stepped=true\",\n",
    "    \n",
    "    f\"https://api1.weather.com/v2/vector-api/products/614/features?x=100&y=62&lod=8&apiKey={weather_api_key}&tile-size=512&time=1730337300000-1730338200000:9&time=1730336400000-1730337300000:24&time=1730335500000-1730336400000:39&time=1730334600000-1730335500000:54&time=1730333700000-1730334600000:68&stepped=true\",\n",
    "    \n",
    "    f\"https://api1.weather.com/v2/vector-api/products/614/features?x=100&y=62&lod=8&apiKey={weather_api_key}&tile-size=512&time=1730337300000-1730338200000:10&time=1730336400000-1730337300000:25&time=1730335500000-1730336400000:40&time=1730334600000-1730335500000:55&time=1730333700000-1730334600000:69&stepped=true\",\n",
    "    \n",
    "    f\"https://api0.weather.com/v2/vector-api/products/614/features?x=50&y=31&lod=7&apiKey={weather_api_key}&tile-size=512&time=1730337300000-1730338200000:10&time=1730336400000-1730337300000:25&time=1730335500000-1730336400000:40&time=1730334600000-1730335500000:55&time=1730333700000-1730334600000:69&stepped=true\",\n",
    "    \n",
    "    f\"https://api0.weather.com/v2/vector-api/products/614/features?x=50&y=31&lod=7&apiKey={weather_api_key}&tile-size=512&time=1730337300000-1730338200000:11&time=1730336400000-1730337300000:26&time=1730335500000-1730336400000:41&time=1730334600000-1730335500000:56&time=1730333700000-1730334600000:70&stepped=true\",\n",
    "    \n",
    "    f\"https://api3.weather.com/v2/vector-api/products/5999/features?x=101&y=63&lod=8&apiKey={weather_api_key}&tile-size=512&time=1730337907000&stepped=true\",\n",
    "    \n",
    "    f\"https://api2.weather.com/v2/vector-api/products/614/features?x=51&y=32&lod=7&apiKey={weather_api_key}&tile-size=512&time=1730337300000-1730338200000:13&time=1730336400000-1730337300000:28&time=1730335500000-1730336400000:43&time=1730334600000-1730335500000:58&time=1730333700000-1730334600000:72&stepped=true\",\n",
    "    \n",
    "    f\"https://api0.weather.com/v2/vector-api/products/614/features?x=103&y=63&lod=8&apiKey={weather_api_key}&tile-size=512&time=1730337300000-1730338200000:14&time=1730336400000-1730337300000:29&time=1730335500000-1730336400000:44&time=1730334600000-1730335500000:59&time=1730333700000-1730334600000:73&stepped=true\",\n",
    "    \n",
    "    f\"https://api2.weather.com/v2/vector-api/products/614/features?x=52&y=31&lod=7&apiKey={weather_api_key}&tile-size=512&time=1730337300000-1730338200000:14&time=1730336400000-1730337300000:29&time=1730335500000-1730336400000:44&time=1730334600000-1730335500000:59&time=1730333700000-1730334600000:73&stepped=true\",\n",
    "    \n",
    "    f\"https://api1.weather.com/v2/vector-api/products/5999/features?x=52&y=30&lod=7&apiKey={weather_api_key}&tile-size=512&time=1730337907000&stepped=true\",\n",
    "    \n",
    "    f\"https://api2.weather.com/v2/vector-api/products/5999/features?x=53&y=30&lod=7&apiKey={weather_api_key}&tile-size=512&time=1730337907000&stepped=true\",\n",
    "    \n",
    "    f\"https://api0.weather.com/v2/vector-api/products/614/features?x=26&y=15&lod=6&apiKey={weather_api_key}&tile-size=512&time=1730338200000-1730339100000:0&time=1730337300000-1730338200000:15&time=1730336400000-1730337300000:30&time=1730335500000-1730336400000:45&time=1730334600000-1730335500000:60&stepped=true\",\n",
    "    \n",
    "    f\"https://api.weather.com/v2/vector-api/products/614/features?x=25&y=15&lod=6&apiKey={weather_api_key}&tile-size=512&time=1730338200000-1730339100000:0&time=1730337300000-1730338200000:15&time=1730336400000-1730337300000:30&time=1730335500000-1730336400000:45&time=1730334600000-1730335500000:60&stepped=true\",\n",
    "    \n",
    "    f\"https://api1.weather.com/v2/vector-api/products/614/features?x=26&y=16&lod=6&apiKey={weather_api_key}&tile-size=512&time=1730338200000-1730339100000:0&time=1730337300000-1730338200000:15&time=1730336400000-1730337300000:30&time=1730335500000-1730336400000:45&time=1730334600000-1730335500000:60&stepped=true\",\n",
    "    \n",
    "    f\"https://api2.weather.com/v2/vector-api/products/614/features?x=199&y=124&lod=9&apiKey={weather_api_key}&tile-size=512&time=1730340000000-1730340900000:3&time=1730339100000-1730340000000:18&time=1730338200000-1730339100000:33&time=1730337300000-1730338200000:48&time=1730336400000-1730337300000:63&stepped=true\",\n",
    "    \n",
    "    f\"https://api0.weather.com/v2/vector-api/products/614/features?x=201&y=125&lod=9&apiKey={weather_api_key}&tile-size=512&time=1730340000000-1730340900000:5&time=1730339100000-1730340000000:20&time=1730338200000-1730339100000:35&time=1730337300000-1730338200000:50&time=1730336400000-1730337300000:65&stepped=true\",\n",
    "    \n",
    "    f\"https://api.weather.com/v2/vector-api/products/614/features?x=200&y=125&lod=9&apiKey={weather_api_key}&tile-size=512&time=1730340000000-1730340900000:5&time=1730339100000-1730340000000:20&time=1730338200000-1730339100000:35&time=1730337300000-1730338200000:50&time=1730336400000-1730337300000:65&stepped=true\",\n",
    "    \n",
    "    f\"https://api0.weather.com/v2/vector-api/products/614/features?x=200&y=126&lod=9&apiKey={weather_api_key}&tile-size=512&time=1730340000000-1730340900000:6&time=1730339100000-1730340000000:21&time=1730338200000-1730339100000:36&time=1730337300000-1730338200000:51&time=1730336400000-1730337300000:66&stepped=true\",\n",
    "    \n",
    "    f\"https://api1.weather.com/v2/vector-api/products/614/features?x=400&y=252&lod=10&apiKey={weather_api_key}&tile-size=512&time=1730340000000-1730340900000:6&time=1730339100000-1730340000000:21&time=1730338200000-1730339100000:36&time=1730337300000-1730338200000:51&time=1730336400000-1730337300000:66&stepped=true\",\n",
    "    \n",
    "    f\"https://api2.weather.com/v2/vector-api/products/614/features?x=100&y=63&lod=8&apiKey={weather_api_key}&tile-size=512&time=1730340000000-1730340900000:7&time=1730339100000-1730340000000:22&time=1730338200000-1730339100000:37&time=1730337300000-1730338200000:52&time=1730336400000-1730337300000:67&stepped=true\",\n",
    "    \n",
    "    f\"https://api1.weather.com/v2/vector-api/products/614/features?x=201&y=126&lod=9&apiKey={weather_api_key}&tile-size=512&time=1730340000000-1730340900000:7&time=1730339100000-1730340000000:22&time=1730338200000-1730339100000:37&time=1730337300000-1730338200000:52&time=1730336400000-1730337300000:67&stepped=true\",\n",
    "    \n",
    "    f\"https://api3.weather.com/v2/vector-api/products/614/features?x=797&y=497&lod=11&apiKey={weather_api_key}&tile-size=512&time=1730340000000-1730340900000:8&time=1730339100000-1730340000000:23&time=1730338200000-1730339100000:38&time=1730337300000-1730338200000:53&time=1730336400000-1730337300000:68&stepped=true\",\n",
    "    \n",
    "    f\"https://api3.weather.com/v2/vector-api/products/614/features?x=798&y=496&lod=11&apiKey={weather_api_key}&tile-size=512&time=1730340000000-1730340900000:8&time=1730339100000-1730340000000:23&time=1730338200000-1730339100000:38&time=1730337300000-1730338200000:53&time=1730336400000-1730337300000:68&stepped=true\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Station:\n",
    "    def __init__(self, name, lat, long, area):\n",
    "        self.name = name\n",
    "        self.lat = lat\n",
    "        self.long = long\n",
    "        self.area = area\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Station: {self.name}, Area: {self.area}, Long: {self.long}, Lat: {self.lat}\"\n",
    "\n",
    "\n",
    "stations = []\n",
    "station_names = []\n",
    "\n",
    "for url in urls:\n",
    "    print(\"Requesting\", url)\n",
    "    res = requests.get(url)\n",
    "    res.raise_for_status()\n",
    "    \n",
    "    res = res.json()\n",
    "    \n",
    "    for key in res:\n",
    "        location_data = res[key]\n",
    "        type = location_data[\"type\"]\n",
    "        features = location_data[\"features\"]\n",
    "\n",
    "        if type != \"FeatureCollection\":\n",
    "            print(\"Error, type is not FeatureCollection\")\n",
    "\n",
    "        for station in features:\n",
    "            geom = station[\"geometry\"]\n",
    "            if geom[\"type\"] != \"Point\":\n",
    "                print(\"Error, geometry type is not Point\")\n",
    "            long, lat = geom[\"coordinates\"][0], geom[\"coordinates\"][1]\n",
    "\n",
    "            station_name = station[\"id\"]\n",
    "            properties = station[\"properties\"]\n",
    "            \n",
    "            if \"country\" not in properties: # likely airport\n",
    "                airport = properties[\"station_name\"]\n",
    "                print(\"Some properties not found for\", airport, \"stationID\", station_name)\n",
    "                continue\n",
    "                \n",
    "            country = properties[\"country\"]\n",
    "            neighbourhood = properties[\"neighborhood\"]\n",
    "            if properties[\"type\"] != \"PWS\":\n",
    "                print(\"Error, properties type is not PWS\")\n",
    "\n",
    "            if country != \"MY\":\n",
    "                continue\n",
    "\n",
    "            if station_name in station_names:\n",
    "                continue\n",
    "            station_names.append(station_name)\n",
    "            stations.append(Station(station_name, lat, long, neighbourhood))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requesting IJERAN4\n",
      "Requesting IKUALA30\n",
      "Requesting IBEHRA1\n",
      "Requesting IKUANT7\n",
      "Requesting IKAJAN2\n",
      "Requesting IRAUB4\n",
      "Requesting IBRINC2\n",
      "Requesting IKLANG3\n",
      "Requesting IKAJAN12\n",
      "Requesting IAYERH4\n",
      "Requesting INEGER3\n",
      "Requesting ITANGK2\n",
      "Requesting IMALAC33\n",
      "Requesting IKULAI10\n",
      "Requesting ISIBU12\n",
      "Requesting IKOTAS4\n",
      "Requesting ILABUA2\n",
      "Requesting IPENAN4\n",
      "Requesting IRANTA10\n",
      "Requesting IRANTA13\n",
      "Requesting ITAIPI2\n",
      "Requesting IRANTA14\n",
      "Requesting ICHERAS7\n",
      "Requesting IKULAI13\n"
     ]
    }
   ],
   "source": [
    "#ILABUA2\n",
    "df = pd.read_csv(\"dbt/seeds/state_locations.csv\")\n",
    "identified_stations = df[~df['PWStation'].isna()]['PWStation'].to_list()\n",
    "\n",
    "new_stations = []\n",
    "for station in stations:\n",
    "    if station.name not in identified_stations:\n",
    "        new_stations.append(station)\n",
    "        \n",
    "geolocator = Nominatim(user_agent=\"weather_app\")\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "def breakdown_address(lat, long):\n",
    "    raw_add = geolocator.reverse(f\"{lat}, {long}\").raw['address']\n",
    "    \n",
    "    town = next((raw_add[key] for key in ['town', 'hamlet', 'county', 'suburb', 'neighbourhood', 'quarter', 'district'] if raw_add.get(key)), None)\n",
    "    city = next((raw_add[key] for key in ['city', 'district', 'state_district', 'county', 'region', 'suburb'] if raw_add.get(key)), None)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        \"Identifying_Location\": [town],\n",
    "        \"Place\": [city],\n",
    "        \"Latitude\": [lat],\n",
    "        \"Longitude\": [long],\n",
    "        \"Postcode\": [raw_add.get('postcode')],\n",
    "        \"ICAO\": \"\",\n",
    "        \"PWStation\": \"\",\n",
    "        \"Missing_Data\": \"\",\n",
    "        \"address\": [raw_add]\n",
    "    })\n",
    "    return df\n",
    "    \n",
    "for station in new_stations:\n",
    "    print(\"Requesting\", station.name)\n",
    "    lat, long = station.lat, station.long\n",
    "    try:\n",
    "        df = breakdown_address(lat, long)\n",
    "        new_df = pd.concat([new_df, df], axis=0, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"Error, skipping\", station.name)\n",
    "        continue\n",
    "    \n",
    "new_df.to_csv(\"new_sl.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check missing aq days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-10-30\n",
      "2024-10-31\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "df = pd.read_csv(\"data/bq-results-20241031-073952-1730360413626.csv\")\n",
    "new_df = df.drop_duplicates()\n",
    "\n",
    "new_df.sort_values(['aq_date'])\n",
    "defined_dates = new_df['aq_date'].to_list()\n",
    "\n",
    "datelist = pd.date_range(datetime(2024,1,1), datetime.today(), freq='D').to_list()\n",
    "\n",
    "for date in datelist:\n",
    "    date = date.strftime(\"%Y-%m-%d\")\n",
    "    if date not in new_df['aq_date'].to_list():\n",
    "        print(date)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.etl.extract.extract_weather import request_data\n",
    "from prefect.tasks import task\n",
    "\n",
    "res = requests.get(\"https://api.weather.com/v1/location/WBGN:9:MY/observations/historical.json?apiKey=e1f10a1e78da46f5b10a1e78da96f525&units=m&startDate=20241028&endDate=20241028\")\n",
    "\n",
    "# request_data('2024-01-01', '2024-02-02', 'WBGN:9:MY')\n",
    "coroutine = request_data.fn('20240101', '20240101', 'WBGN:9:MY')\n",
    "\n",
    "await coroutine\n",
    "\n",
    "python main.py \\\n",
    "  --testing \\\n",
    "  --personal_weather \\\n",
    "  --start_date=20241001 \\\n",
    "  --end_date=20241001 \\\n",
    "  --time=0000 \\\n",
    "  --stations WBGN WXMX \\\n",
    "  --parallel=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shahmir.lourdusamy/Development/quality-of-life/venv/lib/python3.11/site-packages/urllib3/connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'eqmp.doe.gov.my'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\"https://eqmp.doe.gov.my/api2/publicportalapims/apitablehourly?stateid=10&datetime=2024-11-01T00:00:00&\", verify=False)\n",
    "response.raise_for_status()\n",
    "\n",
    "response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from datetime import datetime\n",
    "\n",
    "class AQ_Reading:\n",
    "    def __init__(self, station_id, state_id, station_name, station_location, datetime, api):\n",
    "        self.station_id = station_id\n",
    "        self.state_id = state_id\n",
    "        self.station_name = station_name\n",
    "        self.station_location = station_location\n",
    "        self.datetime = datetime\n",
    "        self.api = api\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f\"Station: {self.station_name}, Location: {self.station_location}, Datetime: {self.datetime}, API: {self.api}\"\n",
    "\n",
    "def extract_aq(response: dict) -> List[AQ_Reading]:\n",
    "    if 'api_table_hourly' not in response:\n",
    "        print(\"Error, api_table_hourly not found\")\n",
    "        return\n",
    "        \n",
    "    readings = response['api_table_hourly']\n",
    "    if len(readings) == 0:\n",
    "        print(\"Error, no readings found\")\n",
    "        return\n",
    "    \n",
    "    aq_readings = []\n",
    "    for reading in readings:\n",
    "        \n",
    "        reading_time = reading['DATETIME']\n",
    "        if not isinstance(reading_time, datetime):\n",
    "            reading_time = datetime.strptime(reading_time, \"%Y-%m-%dT%H:%M:%S\")\n",
    "        \n",
    "        aq_reading = AQ_Reading(reading['STATION_ID'], reading['STATE_ID'], reading['STATION_NAME'], reading['STATION_LOCATION'], reading_time, reading['API'])\n",
    "        aq_readings.append(aq_reading)\n",
    "        \n",
    "    return aq_readings\n",
    "\n",
    "\n",
    "locations = []\n",
    "for i in range(1, 16):\n",
    "    response = requests.get(f\"https://eqmp.doe.gov.my/api2/publicportalapims/apitablehourly?stateid={i}&datetime=2024-11-01T00:00:00&\", verify=False)\n",
    "    response.raise_for_status()\n",
    "    response = response.json()\n",
    "    \n",
    "    data = extract_aq(response)\n",
    "    for d in data:\n",
    "        if d.station_location not in locations:\n",
    "            locations.append(d.station_location)\n",
    "\n",
    "\n",
    "print(locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "places = [location.split(',')[0] for location in locations]\n",
    "df = pd.read_csv(\"dbt/seeds/state_locations.csv\")\n",
    "\n",
    "for place in places:\n",
    "    if place not in df['Identifying_Location'].to_list():\n",
    "        print(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2192423803.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    python main.py \\\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python main.py \\\n",
    "    --testing \\\n",
    "    --personal_weather \\\n",
    "    --stations IJERAN4 IKUALA30 IBEHRA1 IKUANT7 IKAJAN2 IRAUB4 IBRINC2 IKLANG3 IKAJAN12 IAYERH4 INEGER3 ITANGK2 IMALAC33 IKULAI10 ISIBU12 IKOTAS4 ILABUA2 IPENAN4 IRANTA10 IRANTA13 ITAIPI2 ICHERAS7 IKUALI13 IPENAN5 \\\n",
    "    --start_date=20240701 \\\n",
    "    --end_date=20241030 \\\n",
    "    --time=0000 \\\n",
    "    --parallel=1\n",
    "  \n",
    "    \"IJERAN4\",\n",
    "    \"IKUALA30\",\n",
    "    \"IBEHRA1\",\n",
    "    \"IKUANT7\",\n",
    "    \"IKAJAN2\",\n",
    "    \"IRAUB4\",\n",
    "    \"IBRINC2\",\n",
    "    \"IKLANG3\",\n",
    "    \"IKAJAN12\",\n",
    "    \"IAYERH4\",\n",
    "    \"INEGER3\",\n",
    "    \"ITANGK2\",\n",
    "    \"IMALAC33\",\n",
    "    \"IKULAI10\",\n",
    "    \"ISIBU12\",\n",
    "    \"IKOTAS4\",\n",
    "    \"ILABUA2\",\n",
    "    \"IPENAN4\",\n",
    "    \"IRANTA10\",\n",
    "    \"IRANTA13\",\n",
    "    \"ITAIPI2\",\n",
    "    \"ICHERAS7\",\n",
    "    \"IKUALI13\",\n",
    "    \"IPENAN5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dbt/seeds/state_locations.csv\")\n",
    "df_city = pd.read_csv(\"dbt/seeds/city_places.csv\")\n",
    "\n",
    "act_places = df['Place'].to_list()\n",
    "places = df_city['Place'].to_list()\n",
    "\n",
    "for place in act_places:\n",
    "    if place not in places:\n",
    "        print(place)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Identifying_Location</th>\n",
       "      <th>Place</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>PWStation</th>\n",
       "      <th>Missing_Data</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Identifying_Location, Place, Latitude, Longitude, Postcode, ICAO, PWStation, Missing_Data, Address]\n",
       "Index: []"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dbt/seeds/state_locations.csv\")\n",
    "df[df['PWStation'].duplicated() & df['PWStation'].notna()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
